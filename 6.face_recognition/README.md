# Homework6
`jskyzero` `2018/01/13`

## 原理

使用PCA对数据进行一次降维。再使用一般性的方法来对向量的相似性进行比较。

## 要求

算法描述和文档、代码和测试性能表格，必要的图像等。

+ 算法描述：这里的实现采用的是计算特征值/特征向量优化后的PCA降维搭配一般的二范式比较向量相似性方法。具体的算法流程可以参考参考文档的流程。
+ 代码：请参考目录其他代码文件。使用的都是之前的接触过的基本函数，似乎没有使用任何`Matlab的工具库`。
+ 测试性能表格：请参考下面的讨论。
+ 必要的图像：似乎没有什么图像是必要的，最后的参数讨论可以采用绘图的形式，不过这里已经打印表格了。另外如果在中途尝试复原原图像实际上和参考文档中的效果类似，根据K的选取图像损失了一定的细节。

## 一些讨论

### 关于影响性能的因素

抛开代码实现优化的部分不谈，在算法上，主要影响性能的两个问题是，计算特征值/特征向量的时候是否采用了优化后的方法，在这里将可以把`112*92 = 10304`的方矩的优化为`40 * 7 = 280`的方矩，速度提升还是可以直接感觉到的。另外一个问题是K的选取，显然K越大需要的时间越长。

### 关于影响结果的因素
首先我们先来看K值吧。
```
>> run('C:\Users\jskyzero\workspace\playground\Digit-Image-Propressing\6.face_recognition\main.m')
k=2.000000 Means: 0.400000 Max: 0.466667 Min: 0.358333
k=4.000000 Means: 0.790833 Max: 0.841667 Min: 0.758333
k=8.000000 Means: 0.925833 Max: 0.975000 Min: 0.900000
k=16.000000 Means: 0.955833 Max: 0.983333 Min: 0.916667
k=32.000000 Means: 0.971667 Max: 0.991667 Min: 0.941667
k=64.000000 Means: 0.968333 Max: 0.983333 Min: 0.950000
```
可以看到，K比较小的时候，随着K的增加，性能会变好，但是K达到一定大小后，继续增加反而效果会下降，因为图像中是存在噪声等等干扰的，过分的细节反而使得准确率下降。

另外在训练/测试的比例上，这里采用了要求的7：3，理论上来说，训练的量越大效果越好。

最后在具体的两个向量的比较上，除了一范式，二范式外，还有直接比较不同的位的个数，采用余弦定理比较向量的夹角等做法，这里不再具体更换比较差异，比较函数的好坏一般是跟数据相关的。